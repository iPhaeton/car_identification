{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from constants import img_size\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.layers import Input, Dense, Flatten, subtract\n",
    "from keras.models import Model\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seamese_Model:\n",
    "    def __init__(self, base_model, opts, kernel_opts=None, bias_opts=None):\n",
    "        self.base_model = base_model\n",
    "        self.opts = opts\n",
    "        self.kernel_opts = kernel_opts\n",
    "        self.bias_opts = bias_opts\n",
    "    \n",
    "    def kernel_initializer(self, shape, name=None):\n",
    "        if (self.kernel_opts != None):\n",
    "            values = np.random.normal(loc=self.kernel_opts['loc'], scale=self.kernel_opts['scale'], size=shape)\n",
    "            return K.variable(values, name=name)\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    def bias_initializer(self, shape, name=None):\n",
    "        if (self.bias_opts != None):\n",
    "            values = np.random.normal(loc=self.bias_opts['loc'], scale=self.bias_opts['scale'], size=shape)\n",
    "            return K.variable(values, name=name)\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    def get_top_model(self):\n",
    "        input_1 = Input(self.opts['features_shape'])\n",
    "        input_2 = Input(self.opts['features_shape'])\n",
    "        \n",
    "        X_1 = Flatten()(input_1)\n",
    "        X_2 = Flatten()(input_2)\n",
    "        distance = subtract([X_1, X_2])\n",
    "\n",
    "        prediction = Dense(1, activation='sigmoid', bias_initializer=self.bias_initializer, name='log_reg')(distance)\n",
    "        model = Model(input=[input_1, input_2], output=prediction)\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"lo...)`\n"
     ]
    }
   ],
   "source": [
    "model = Seamese_Model(\n",
    "    ResNet50, \n",
    "    opts={\n",
    "        'weights': 'imagenet',\n",
    "        'input_shape': (img_size, img_size, 3),\n",
    "        'features_shape': (1, 2048),\n",
    "        'pooling': 'avg',\n",
    "    },\n",
    "    kernel_opts={\n",
    "        'loc': 0,\n",
    "        'scale': 1e-2,\n",
    "    },\n",
    "    bias_opts={\n",
    "        'loc': 0.5,\n",
    "        'scale': 1e-2,\n",
    "    }\n",
    ")\n",
    "\n",
    "model = model.get_top_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1, 2048)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1, 2048)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 2048)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 2048)         0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "subtract_1 (Subtract)           (None, 2048)         0           flatten_1[0][0]                  \n",
      "                                                                 flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_reg (Dense)                 (None, 1)            2049        subtract_1[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 2,049\n",
      "Trainable params: 2,049\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervisor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Supervisor:\n",
    "    # use seed only for testing\n",
    "    def __init__(self, model, data_train, classes_train, data_dev, classes_dev, seed=None):\n",
    "        self.model = model\n",
    "        self.data_train = data_train\n",
    "        self.classes_train = classes_train\n",
    "        self.data_dev = data_dev\n",
    "        self.classes_dev = classes_dev\n",
    "        self.seed = seed\n",
    "        \n",
    "    def get_pair(self, index_1, index_2):\n",
    "        el_1 = np.take(self.data_train, [index_1], axis=0)\n",
    "        el_2 = np.take(self.data_train, [index_2], axis=0)\n",
    "        return([el_1, el_2])\n",
    "    \n",
    "    def get_selection_index(self, index, indices):\n",
    "        selection_index = index\n",
    "        while selection_index == index:\n",
    "            selection_index = np.random.choice(indices, 1)[0]\n",
    "        return selection_index\n",
    "    \n",
    "    def get_batch(self, n):\n",
    "        np.random.seed(self.seed)\n",
    "        indices = np.random.choice(list(range(len(self.data_train))), size=n)\n",
    "        \n",
    "        pairs = []\n",
    "        y = []\n",
    "        \n",
    "        for index in indices[:n//2]:\n",
    "            selection_indices = np.argwhere(self.classes_train == self.classes_train[index]).flatten()\n",
    "            selection_index = self.get_selection_index(index, selection_indices)\n",
    "            pairs.append(self.get_pair(index, selection_index))\n",
    "            y.append(1)\n",
    "            \n",
    "        for index in indices[n//2:]:\n",
    "            selection_indices = np.argwhere(self.classes_train != self.classes_train[index]).flatten()\n",
    "            selection_index = self.get_selection_index(index, selection_indices)\n",
    "            pairs.append(self.get_pair(index, selection_index))\n",
    "            y.append(0)\n",
    "\n",
    "        return (np.array(pairs), np.array(y))\n",
    "    \n",
    "    def train(self, iterations, batch_size, learning_rate=0.0001, path=None):\n",
    "        self.model.compile(optimizer=tf.train.AdamOptimizer(learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['acc'])\n",
    "        \n",
    "        if path != None:\n",
    "            self.model.load_weights(path)\n",
    "        \n",
    "        for i in tqdm(range(iterations)):\n",
    "            inputs, targets = self.get_batch(batch_size)\n",
    "            self.model.train_on_batch([inputs[:,0,:], inputs[:,1,:]], targets)\n",
    "    \n",
    "    def get_validation_task(self, index):\n",
    "        targets = np.repeat(np.take(self.data_dev, [index], axis=0), self.data_dev.shape[0] - 1, axis=0)\n",
    "        support_set = np.delete(self.data_dev, index, axis=0)\n",
    "        pairs = np.stack([targets, support_set], axis=1)\n",
    "        return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = np.load('./data/features/res_net/features_train.npy')\n",
    "classes_train = np.load('./data/features/res_net/classes_train.npy')\n",
    "features_dev = np.load('./data/features/res_net/features_dev.npy')\n",
    "classes_dev = np.load('./data/features/res_net/classes_dev.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervisor = Supervisor(model, features_train, classes_train, features_dev, classes_dev, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 96.49it/s]\n"
     ]
    }
   ],
   "source": [
    "supervisor.train(100, 128)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.lstm_encoder_decoder import LSTMEncoderDecoder\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import LSTM, SimpleRNN, Input, Bidirectional, TimeDistributed, Dropout, Dense, Activation, BatchNormalization\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown, Latex, HTML, clear_output\n",
    "import ipy_table\n",
    "import ipywidgets as widgets\n",
    "from scipy import ndimage\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classnames(classes, classnames):\n",
    "    class_to_classname = {}\n",
    "    for cl, classname in zip(true_classes, true_classnames):\n",
    "        class_to_classname[cl] = classname\n",
    "\n",
    "    unique_classnames = []\n",
    "    for i in range(len(class_to_classname)):\n",
    "        unique_classnames.append(class_to_classname[i])\n",
    "        \n",
    "    return np.array(unique_classnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.load('../input/features/lstm/3_steps/indices_dev.npy')\n",
    "true_classes = np.load('../input/features/res_net/classes_dev_make-model.npy')[indices]\n",
    "true_classnames = np.load('../input/features/res_net/classnames_dev_make-model.npy')[indices]\n",
    "true_filenames = np.load('../input/features/res_net/filenames_dev.npy')[indices]\n",
    "unique_classnames = get_classnames(true_classes, true_classnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_predictions_to_classnames(predictions, true_classes, classnames):\n",
    "    classes, indices = np.unique(true_classes, return_index=True)\n",
    "    \n",
    "    class_to_index = {}\n",
    "    for cl, index in zip(classes, indices):\n",
    "        class_to_index[cl] = index\n",
    "    \n",
    "    predicted_classnames = list(map(lambda cl: classnames[class_to_index[cl]], predictions))\n",
    "    return np.array(predicted_classnames)\n",
    "\n",
    "def map_indices_to_classnames(indices, classnames):\n",
    "    return np.array(list(map(lambda i: classnames[i], indices)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM Encoder-Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_decoder = LSTMEncoderDecoder(\n",
    "    source_path='../input/features/lstm/3_steps/',\n",
    "    weights_path='../input/convnet_weights/weights.04-0.36-87.85.hdf5',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, probs = encoder_decoder.predict('dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classnames = map_predictions_to_classnames(predictions, true_classes, true_classnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probs = np.max(probs, axis=1)\n",
    "true_class_probs = probs[list(range(len(true_classes))), true_classes]\n",
    "five_top_classes = np.flip(np.argsort(probs, axis=1), axis=1)[:,0:5]\n",
    "five_top_probs = np.array(list(map(lambda f: str(f), np.flip(np.sort(probs, axis=1), axis=1)[:,0:5])))\n",
    "five_top_names = np.array(list(map(lambda f: str(f), map_indices_to_classnames(five_top_classes, unique_classnames))))\n",
    "five_top_correct = list(map(lambda v: np.isin(v[0], v[1]), zip(true_classes, five_top_classes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reports creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, indices = np.unique(true_classes, return_index=True)\n",
    "classnames = true_classnames[indices]\n",
    "directories = list(map(lambda f: f.split('/')[0],true_filenames[indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_report = pd.DataFrame({\n",
    "    'name': classnames,\n",
    "    'directory': directories,\n",
    "}, index = classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_classnames = list(map(lambda cl: classes_report['name'][cl], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_report = pd.DataFrame({\n",
    "    'filename': true_filenames,\n",
    "    'prediction': predictions,\n",
    "    'real_class': true_classes,\n",
    "    'predicted_name': pred_classnames,\n",
    "    'real_name': true_classnames,\n",
    "    'predicted_correctly': predictions == true_classes,\n",
    "    'five_top_prediction_correct': five_top_correct,\n",
    "    'predicted_prob': predicted_probs,\n",
    "    'true_class_prob': true_class_probs,\n",
    "    'five_top_names': five_top_names,\n",
    "    'five_top_probs': five_top_probs,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_count = samples_report['real_class'].value_counts()\n",
    "classes_report['count'] = classes_count.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_count = samples_report[samples_report['predicted_correctly'] == True]['real_class'].value_counts()\n",
    "classes_report['correct_predictions_count'] = correct_count.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_report['correct_predictions_percent'] = classes_report['correct_predictions_count'] / classes_report['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Accuracy', samples_report[samples_report['predicted_correctly'] == True].shape[0] / samples_report.shape[0])\n",
    "print ('Five top accuracy', samples_report[samples_report['five_top_prediction_correct'] == True].shape[0] / samples_report.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_report():\n",
    "    clear_output()\n",
    "    display(widgets.HBox((dropdown_sort, dropdown_direction)))\n",
    "\n",
    "def display_classes_report(sortBy, direction):\n",
    "    html = pd.DataFrame.to_html(classes_report.sort_values(sortBy, ascending=direction))\n",
    "    display(HTML(html))\n",
    "    \n",
    "def clear_and_display_report(sortBy, direction):\n",
    "    clear_report()\n",
    "    display_classes_report(sortBy, direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dropdown_sort = widgets.Dropdown(\n",
    "    options=['correct_predictions_percent', 'name', 'count'],\n",
    "    value='correct_predictions_percent',\n",
    "    description='Sort by:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "dropdown_direction = widgets.Dropdown(\n",
    "    options=['ascending', 'descending'],\n",
    "    value='ascending',\n",
    "    description='Direction:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "dropdown_sort.observe(lambda v: \n",
    "                          clear_and_display_report(v['new'], dropdown_direction.value == 'ascending') \n",
    "                          if v['name'] == 'value'\n",
    "                          else None\n",
    "                     )\n",
    "dropdown_direction.observe(lambda v: \n",
    "                              clear_and_display_report(dropdown_sort.value, v['new'] == 'ascending') \n",
    "                              if v['name'] == 'value'\n",
    "                              else None\n",
    "                          )\n",
    "\n",
    "clear_and_display_report(dropdown_sort.value, dropdown_direction.value == 'ascending')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samples report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dropdown_classes = None\n",
    "dropdown_correctness = None\n",
    "dropdown_sample = None\n",
    "\n",
    "def show_sample(row):\n",
    "    clear_output()\n",
    "    display(widgets.HBox((dropdown_classes, dropdown_correctness)))\n",
    "    display(dropdown_sample)\n",
    "    \n",
    "    image = np.array(plt.imread('../input/car_data/' + row['filename'].iloc[0]))\n",
    "    plt.imshow(image)\n",
    "    print('Classified as: ', row['predicted_name'].iloc[0])\n",
    "    print('Predicted probability: ', row['predicted_prob'].iloc[0])\n",
    "    print('Correct class probability: ', row['true_class_prob'].iloc[0])\n",
    "    print('Five top predictions: ', row['five_top_names'].iloc[0])\n",
    "    print('Five top prediction probs: ', row['five_top_probs'].iloc[0])\n",
    "    filenames = samples_report[samples_report['real_name'] == row['predicted_name'].iloc[0]]['filename']\n",
    "    \n",
    "    images = []\n",
    "    for filename in filenames[0:100]:\n",
    "        images.append(filename)\n",
    "        \n",
    "    fig = plt.figure(figsize=(20,40))\n",
    "    for k in range(10):\n",
    "        for i, image in enumerate(images[k*3:k*3+3]):\n",
    "            img = np.array(plt.imread('../input/car_data/' + image))\n",
    "            ax = fig.add_subplot(10,3,i + 1 + k * 3)\n",
    "            ax.imshow(img)\n",
    "\n",
    "\n",
    "def show_samples(classname, classification):\n",
    "    global dropdown_sample\n",
    "\n",
    "    df = samples_report[\n",
    "        (samples_report['real_name'] == classname) &\n",
    "        (samples_report['predicted_correctly'] == classification)\n",
    "    ]\n",
    "\n",
    "    if df.shape[0] == 0:\n",
    "        return\n",
    "\n",
    "    dropdown_sample = widgets.Dropdown(\n",
    "        options=df['filename'],\n",
    "        value=df['filename'].iloc[0],\n",
    "        disabled=False,\n",
    "    )\n",
    "    \n",
    "    dropdown_sample.observe(lambda v: show_sample(df[df['filename'] == v['new']]), names='value')\n",
    "    \n",
    "    display(dropdown_sample)\n",
    "    show_sample(df[df['filename'] == df['filename'].iloc[0]])\n",
    "\n",
    "def observe_classes(v):\n",
    "    clear_output()\n",
    "    display(widgets.HBox((dropdown_classes, dropdown_correctness)))\n",
    "    show_samples(v['new'], dropdown_correctness.value == 'classified correctly')\n",
    "    \n",
    "def observe_correctness(v):\n",
    "    clear_output()\n",
    "    show_samples(dropdown_classes.value, v['new'] == 'classified correctly')\n",
    "\n",
    "dropdown_classes = widgets.Dropdown(\n",
    "    options=classnames,\n",
    "    value=classnames[0],\n",
    "    description='Class:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "dropdown_correctness = widgets.Dropdown(\n",
    "    options=['misclassified', 'classified correctly'],\n",
    "    value='misclassified',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "dropdown_classes.observe(observe_classes, names='value')\n",
    "dropdown_correctness.observe(observe_correctness, names='value')\n",
    "\n",
    "display(widgets.HBox((dropdown_classes, dropdown_correctness)))\n",
    "show_samples(classnames[0], dropdown_correctness.value == 'classified correctly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misclassified as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def show_misclassifications(classname):\n",
    "    df = samples_report[(samples_report['predicted_correctly'] == False) & (samples_report['real_name'] == classname)]\n",
    "    df = pd.DataFrame({'Classified as': df['predicted_name']})\n",
    "    html = pd.DataFrame.to_html(df)\n",
    "    display(HTML(html))\n",
    "    \n",
    "def on_change(v):\n",
    "    clear_output()\n",
    "    display(dropdown)\n",
    "    show_misclassifications(v['new'])\n",
    "\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=classnames,\n",
    "    value=classnames[0],\n",
    "    description='Class:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "dropdown.observe(on_change, names='value')\n",
    "\n",
    "display(dropdown)\n",
    "show_misclassifications(classnames[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Dropout\n",
    "from keras.models import Model, Sequential\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input as resnet50_preprocess_input\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input as inception_preprocess_input\n",
    "from keras.applications.xception import Xception, preprocess_input as xception_preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img  \n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import Model\n",
    "\n",
    "from constants import img_size\n",
    "from utils.models import get_base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(datagen, data_dir, batch_size, **kwargs):\n",
    "    print('Data directory:', data_dir)\n",
    "    return datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(img_size, img_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False,\n",
    "        seed=0,\n",
    "        **kwargs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paths(name):\n",
    "    paths_to_create = [\n",
    "        '../input/features/' + name,\n",
    "    ]\n",
    "    \n",
    "    for path in paths_to_create:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "            \n",
    "    return paths_to_create[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractor(model_constructor, name, preprocessor, batch_size, source_dir_train, source_dir_dev, pooling=None, layer=None, verbose = True):\n",
    "    model = get_base_model(model_constructor, img_size, pooling, verbose, layer)\n",
    "\n",
    "    datagen = ImageDataGenerator(preprocessing_function=preprocessor)\n",
    "    generator_train = generator(datagen, source_dir_train, batch_size)\n",
    "    generator_dev = generator(datagen, source_dir_dev, batch_size)\n",
    "    \n",
    "    path = paths(name)\n",
    "    print('Path:', path)\n",
    "    np.save(path + '/filenames_train.npy', generator_train.filenames)\n",
    "    np.save(path + '/classes_train.npy', generator_train.classes)\n",
    "    np.save(path + '/filenames_dev.npy', generator_dev.filenames)\n",
    "    np.save(path + '/classes_dev.npy', generator_dev.classes)\n",
    "    \n",
    "    #train features\n",
    "    features_train = model.predict_generator(generator_train, len(generator_train), verbose=1)\n",
    "    np.save(path + '/features_train.npy', features_train)\n",
    "    \n",
    "    #dev features\n",
    "    features_dev = model.predict_generator(generator_dev, len(generator_dev), verbose=1)\n",
    "    np.save(path + '/features_dev.npy', features_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor(\n",
    "    model_constructor=ResNet50, \n",
    "    name='res_net', \n",
    "    preprocessor=resnet50_preprocess_input, \n",
    "    batch_size=8, \n",
    "#    layer=16,\n",
    "    pooling='avg',\n",
    "    source_dir_train='../input/datasets/train_dataset/',\n",
    "    source_dir_dev='../input/datasets/dev_dataset/',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor(\n",
    "    model_constructor=InceptionV3, \n",
    "    name='inception', \n",
    "    preprocessor=inception_preprocess_input, \n",
    "    batch_size=8, \n",
    "#    layer=16,\n",
    "    pooling='avg',\n",
    "    source_dir_train='../input/datasets/train_dataset/',\n",
    "    source_dir_dev='../input/datasets/dev_dataset/',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor(\n",
    "    model_constructor=Xception, \n",
    "    name='xception', \n",
    "    preprocessor=xception_preprocess_input, \n",
    "    batch_size=8, \n",
    "#    layer=16,\n",
    "    pooling='avg',\n",
    "    source_dir_train='../input/datasets/train_dataset/',\n",
    "    source_dir_dev='../input/datasets/dev_dataset/',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_base_model(Xception, img_size, pooling='avg', verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../input/base_models/xception.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

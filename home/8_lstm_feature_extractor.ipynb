{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import load_model, Model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features from pretrained feature extractors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_indices(net_name, mode):\n",
    "    filenames = np.load('../input/features/' + net_name + '/filenames_' + mode +'.npy')\n",
    "    indices = np.argwhere(np.array(list(map(lambda fn: fn.split('/')[1][0] != '_', filenames))) == True)\n",
    "    indices = indices.reshape((1, indices.shape[0]))[0]\n",
    "    return indices\n",
    "\n",
    "def get_features_from_nets(net_names, mode, steps):\n",
    "    indices = get_indices('res_net', mode)\n",
    "    classes = np.load('../input/features/res_net/classes_' + mode + '_make-model.npy')[indices]\n",
    "    classnames = np.load('../input/features/res_net/classnames_' + mode + '_make-model.npy')[indices]\n",
    "    filenames = np.load('../input/features/res_net/filenames_' + mode + '.npy')[indices]\n",
    "    features = []\n",
    "    for net_name in net_names:\n",
    "        net_features = np.load('../input/features/' + net_name + '/features_' + mode +'.npy')[indices]\n",
    "        features.append(net_features)\n",
    "    features = np.concatenate(features, axis=1)\n",
    "    features = np.expand_dims(features, axis=1)\n",
    "    features = np.repeat(features, steps, axis=1)\n",
    "    return features, classes, classnames, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train, classes_train, classnames_train, filenames_train = get_features_from_nets(['res_net', 'inception', 'xception'], 'train', 3)\n",
    "features_dev, classes_dev, classnames_dev, filenames_dev = get_features_from_nets(['res_net', 'inception', 'xception'], 'dev', 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features from LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "model = load_model('../input/model/car-identification.h5')\n",
    "model = Model(inputs=model.input, outputs=model.layers[6].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3837/3837 [==============================] - 23s 6ms/step\n",
      "996/996 [==============================] - 5s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions_train = model.predict(features_train, verbose=1)\n",
    "predictions_dev = model.predict(features_dev, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divide features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.concatenate((predictions_train, predictions_dev), axis=0)\n",
    "classes = np.concatenate((classes_train, classes_dev), axis=0)\n",
    "classnames = np.concatenate((classnames_train, classnames_dev), axis=0)\n",
    "filenames = np.concatenate((filenames_train, filenames_dev), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4833, 1024) (4833,) (4833,) (4833,)\n"
     ]
    }
   ],
   "source": [
    "print(features.shape, classes.shape, classnames.shape, filenames.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7 11 25 21 30]\n"
     ]
    }
   ],
   "source": [
    "test_classes = np.random.choice(np.unique(classes), 5)\n",
    "print(test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = np.argwhere(np.in1d(classes, test_classes) == False)\n",
    "train_indices = train_indices.reshape((train_indices.shape[0],))\n",
    "dev_indices = np.array([], dtype='int')\n",
    "test_indices = np.array([], dtype='int')\n",
    "\n",
    "for cl in test_classes:\n",
    "    cl_dev_indices, cl_test_indices = train_test_split(np.argwhere(classes == cl), test_size=0.2, random_state=1)\n",
    "    dev_indices = np.append(dev_indices, cl_dev_indices)\n",
    "    test_indices = np.append(test_indices, cl_test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4111,) (576,) (146,)\n"
     ]
    }
   ],
   "source": [
    "print(train_indices.shape, dev_indices.shape, test_indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train_to_save = features[train_indices]\n",
    "classes_train_to_save = classes[train_indices]\n",
    "classnames_train_to_save = classnames[train_indices]\n",
    "filenames_train_to_save = filenames[train_indices]\n",
    "\n",
    "features_dev_to_save = features[dev_indices]\n",
    "classes_dev_to_save = classes[dev_indices]\n",
    "classnames_dev_to_save = classnames[dev_indices]\n",
    "filenames_dev_to_save = filenames[dev_indices]\n",
    "\n",
    "features_test_to_save = features[test_indices]\n",
    "classes_test_to_save = classes[test_indices]\n",
    "classnames_test_to_save = classnames[test_indices]\n",
    "filenames_test_to_save = filenames[test_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../input/features/siamese/features_train.npy', features_train_to_save)\n",
    "np.save('../input/features/siamese/classes_train.npy', classes_train_to_save)\n",
    "np.save('../input/features/siamese/classnames_train.npy', classnames_train_to_save)\n",
    "np.save('../input/features/siamese/filenames_train.npy', filenames_train_to_save)\n",
    "\n",
    "np.save('../input/features/siamese/features_dev.npy', features_dev_to_save)\n",
    "np.save('../input/features/siamese/classes_dev.npy', classes_dev_to_save)\n",
    "np.save('../input/features/siamese/classnames_dev.npy', classnames_dev_to_save)\n",
    "np.save('../input/features/siamese/filenames_dev.npy', filenames_dev_to_save)\n",
    "\n",
    "np.save('../input/features/siamese/features_test.npy', features_test_to_save)\n",
    "np.save('../input/features/siamese/classes_test.npy', classes_test_to_save)\n",
    "np.save('../input/features/siamese/classnames_test.npy', classnames_test_to_save)\n",
    "np.save('../input/features/siamese/filenames_test.npy', filenames_test_to_save)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import urllib\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img, array_to_img, save_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CWD_PATH = os.getcwd()\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "MODEL_NAME = 'mask_rcnn_inception_v2_coco_2018_01_28'\n",
    "MODEL_FILE = MODEL_NAME + '.tar.gz'\n",
    "PATH_TO_CKPT = os.path.join(CWD_PATH, 'modules', MODEL_NAME, 'frozen_inference_graph.pb')\n",
    "PATH_TO_LABELS = os.path.join(CWD_PATH, '../../tensorflow', 'models', 'research', 'object_detection', 'data', 'mscoco_label_map.pbtxt')\n",
    "IMAGE_SIZE = (12, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.join(CWD_PATH, '../../tensorflow','models', 'research'))\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import ops as utils_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image):\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape(\n",
    "        (im_height, im_width, 3)\n",
    "    ).astype(np.uint8)\n",
    "\n",
    "def run_inference_for_single_image(image, graph):\n",
    "    with graph.as_default():\n",
    "        with tf.Session() as sess:\n",
    "          # Get handles to input and output tensors\n",
    "            ops = tf.get_default_graph().get_operations()\n",
    "            all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "            tensor_dict = {}\n",
    "            for key in [\n",
    "              'num_detections', 'detection_boxes', 'detection_scores',\n",
    "              'detection_classes', 'detection_masks'\n",
    "            ]:\n",
    "                tensor_name = key + ':0'\n",
    "                if tensor_name in all_tensor_names:\n",
    "                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "                      tensor_name)\n",
    "            if 'detection_masks' in tensor_dict:\n",
    "                # The following processing is only for single image\n",
    "                detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
    "                detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
    "                # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
    "                real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
    "                detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
    "                detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
    "                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
    "                detection_masks_reframed = tf.cast(\n",
    "                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "                # Follow the convention by adding back the batch dimension\n",
    "                tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "                    detection_masks_reframed, 0)\n",
    "            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "            # Run inference\n",
    "            output_dict = sess.run(tensor_dict,\n",
    "                                 feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
    "\n",
    "            # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "            output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
    "            output_dict['detection_classes'] = output_dict[\n",
    "              'detection_classes'][0].astype(np.uint8)\n",
    "            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "            if 'detection_masks' in output_dict:\n",
    "                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 90\n",
    "\n",
    "# Loading label map\n",
    "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
    "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES,\n",
    "                                                            use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "    od_graph_def = tf.GraphDef()\n",
    "    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
    "        serialized_graph = fid.read()\n",
    "        od_graph_def.ParseFromString(serialized_graph)\n",
    "        tf.import_graph_def(od_graph_def, name='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_box(detections, img_size, indices):\n",
    "    w, h = img_size\n",
    "    \n",
    "    biggest_area = 0\n",
    "    biggest_box = None\n",
    "    index = -1\n",
    "    for i, detection in enumerate(detections):\n",
    "        if i not in indices:\n",
    "            continue\n",
    "        \n",
    "        box = (detection[1] * w, detection[0] * h, detection[3] * w, detection[2] * h)\n",
    "        current_area = (box[2] - box[0]) * (box[3] - box[1])\n",
    "        if current_area > biggest_area:\n",
    "            biggest_area = current_area\n",
    "            biggest_box = box\n",
    "            index = i\n",
    "            \n",
    "    return biggest_box, index\n",
    "\n",
    "def crop_single_image(image_path, verbose=False):\n",
    "    image = load_img(image_path)\n",
    "    # the array based representation of the image will be used later in order to prepare the\n",
    "    # result image with boxes and labels on it.\n",
    "    image_np = load_image_into_numpy_array(image)\n",
    "    # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n",
    "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
    "    # Actual detection.\n",
    "    output_dict = run_inference_for_single_image(image_np, detection_graph)\n",
    "    \n",
    "    indices = np.where(\n",
    "        (output_dict['detection_classes'] == 3) | \n",
    "        (output_dict['detection_classes'] == 6) | \n",
    "        (output_dict['detection_classes'] == 7)\n",
    "    )[0]\n",
    "    box, index = get_box(output_dict['detection_boxes'], image.size, indices)\n",
    "    \n",
    "    mask = output_dict['detection_masks'][index]\n",
    "    mask = np.stack([mask, mask, mask], axis=2)\n",
    "    \n",
    "    output_img = image_np * mask\n",
    "    output_img = array_to_img(output_img)\n",
    "    output_img = output_img.crop(box)\n",
    "    output_img = load_image_into_numpy_array(output_img)\n",
    "    \n",
    "    if verbose == True:\n",
    "        # Visualization of the results of a detection.\n",
    "        vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np,\n",
    "            output_dict['detection_boxes'],\n",
    "            output_dict['detection_classes'],\n",
    "            output_dict['detection_scores'],\n",
    "            category_index,\n",
    "            instance_masks=output_dict.get('detection_masks'),\n",
    "            use_normalized_coordinates=True,\n",
    "            line_thickness=8,\n",
    "            min_score_thresh=0.1\n",
    "        )\n",
    "        plt.figure(figsize=IMAGE_SIZE)\n",
    "        plt.imshow(image_np)\n",
    "    \n",
    "    return output_img, output_dict\n",
    "\n",
    "def filter_files(files_list, filter_by = None):\n",
    "    try:\n",
    "        files_list.remove('.DS_Store')\n",
    "    except:\n",
    "        x=1\n",
    "        \n",
    "    if filter_by is not None:\n",
    "        mask = np.logical_not(np.isin(files_list, filter_by))\n",
    "        result = []\n",
    "        for f, m in zip(files_list, mask):\n",
    "            if m == True:\n",
    "                result.append(f)\n",
    "\n",
    "        return result\n",
    "    else:\n",
    "        return files_list\n",
    "\n",
    "def crop_dir(source_path, target_path, directory):\n",
    "    if os.path.exists(target_path + directory) == False:\n",
    "        os.mkdir(target_path + directory)\n",
    "    \n",
    "    filenames = os.listdir(source_path + directory)\n",
    "    filenames = filter_files(filenames)\n",
    "    \n",
    "    for filename in filenames:\n",
    "        img, _ = crop_single_image(source_path + directory + '/' + filename)\n",
    "        img = array_to_img(img)\n",
    "        save_img(target_path + directory + '/' + filename, img)\n",
    "    \n",
    "def crop(source_path, target_path, dirs):\n",
    "    target_dirs = os.listdir(target_path)\n",
    "    dirs = filter_files(dirs, target_dirs)\n",
    "\n",
    "    if os.path.exists(target_path) == False:\n",
    "        os.mkdir(target_path)\n",
    "    \n",
    "    for i, directory in enumerate(dirs):\n",
    "        print('Directory', str(i), 'of', str(len(dirs)), '...')\n",
    "        crop_dir(source_path, target_path, directory)\n",
    "        print('Images in directory', str(i), '\"' + directory + '\"', 'cropped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirs = ['Bentley Continental_Flying_Spur Sedan 2007',\n",
    " 'Audi TT Coupe 2012 RS',\n",
    " 'Buick Rainier SUV 2007',\n",
    " 'Audi A5 Coupe 2012 S5',\n",
    " 'Chevrolet HHR_SS Hatchback 2010',\n",
    " 'Chevrolet Corvette Coupe 2012 ZR1',\n",
    " 'Audi 100 Wagon 1994',\n",
    " 'Chevrolet Avalanche Crew_Cab 2012',\n",
    " 'Acura ZDX SUV 2012',\n",
    " '.DS_Store',\n",
    " 'Audi TT Coupe 2011',\n",
    " 'Acura TSX Sedan 2012',\n",
    " 'BMW X5 SUV 2007',\n",
    " 'Chevrolet Express_1 Van 2007',\n",
    " 'Bentley Continental_2 Coupe 2012',\n",
    " 'BMW X3 SUV 2012',\n",
    " 'BMW 1_Series Coupe 2012',\n",
    " 'Audi A5 Convertible 2012',\n",
    " 'Aston_Martin V8_Vantage Convertible 2012',\n",
    " 'BMW M3 Coupe 2012',\n",
    " 'Bentley Mulsanne Sedan 2011',\n",
    " 'Chevrolet Corvette Convertible 2012',\n",
    " 'Audi 100 Sedan 1994',\n",
    " 'BMW 6_Series Convertible 2007',\n",
    " 'Audi R8 Coupe 2012',\n",
    " 'Chevrolet Express_1 Cargo_Van 2007',\n",
    " 'Bugatti Veyron Convertible 2009',\n",
    " 'Acura Integra_Type_R Coupe 2001',\n",
    " 'Audi V8 Sedan 1994',\n",
    " 'Buick Enclave SUV 2012',\n",
    " 'Audi A5 Coupe 2012',\n",
    " 'Bugatti Veyron Coupe 2009',\n",
    " 'BMW Z4 Convertible 2012',\n",
    " 'Audi S6 Sedan 2011',\n",
    " 'BMW 1_Series Convertible 2012',\n",
    " 'Chevrolet Express_2 Van 2019',\n",
    " 'Cadillac SRX SUV 2012',\n",
    " 'Acura TL_Type-S Sedan 2008',\n",
    " 'Acura RL Sedan 2012',\n",
    " 'AM Hummer SUV 2000',\n",
    " 'Aston_Martin V8_Vantage Coupe 2012',\n",
    " 'BMW 3_Series_2 Wagon 2010',\n",
    " 'Audi TT Coupe 2012 S',\n",
    " 'Aston_Martin Virage Convertible 2012',\n",
    " 'Audi S4 Sedan 2012',\n",
    " 'Cadillac Escalade_EXT Crew_Cab 2007',\n",
    " 'Audi A5 Convertible 2012 S5',\n",
    " 'Bentley Continental_1 Coupe 2007',\n",
    " 'Chevrolet Cobalt_SS Coupe 2010',\n",
    " 'BMW 3_Series_3 Wagon 2014',\n",
    " 'Buick Verano Sedan 2012',\n",
    " 'Buick Regal_GS Sedan 2012',\n",
    " 'Cadillac CTS-V Sedan 2012',\n",
    " 'BMW 6_Series Convertible 2010 M6',\n",
    " 'Acura TL Sedan 2012',\n",
    " 'Audi A4 Sedan 2007 S4',\n",
    " 'Aston_Martin Virage Coupe 2012',\n",
    " 'Bentley Continental_1 Convertible 2012',\n",
    " 'BMW M5 Sedan 2010',\n",
    " 'Chevrolet Express_2 Cargo_Van 2019',\n",
    " 'Chevrolet Camaro Convertible 2012',\n",
    " 'BMW 5_Series Sedan 2012',\n",
    " 'BMW X6 SUV 2012',\n",
    " 'Chevrolet Corvette Coupe 2007 Z06',\n",
    " 'Bentley Arnage Sedan 2009',\n",
    " 'Audi A4 Convertible 2008 RS_4',\n",
    " 'BMW 3_Series_3 Sedan 2012']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop(\n",
    "    './stanford-car-dataset-by-classes-folder/car_data/', \n",
    "    './stanford-car-dataset-by-classes-folder/cropped_car_data/',\n",
    "    dirs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, output_dict = crop_single_image(\n",
    "    './stanford-car-dataset-by-classes-folder/car_data/Audi TT Coupe 2012 RS/04357.jpg', \n",
    "    True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to use matplotlib inline if want to show at jupyter Notebook\n",
    "%matplotlib inline\n",
    "plt.figure(figsize=IMAGE_SIZE)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = output_dict['detection_classes']\n",
    "print(classes)\n",
    "print(np.where(classes == 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_dict['detection_scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output_dict['detection_classes'].shape, output_dict['detection_boxes'].shape, output_dict['detection_masks'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_map)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

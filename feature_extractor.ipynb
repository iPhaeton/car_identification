{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "from scipy import ndimage\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D, Dropout\n",
    "from keras.models import Model, Sequential\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input as resnet50_preprocess_input\n",
    "from keras.applications.inception_v3 import InceptionV3, preprocess_input as inception_preprocess_input\n",
    "from keras.applications.xception import Xception, preprocess_input as xception_preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img  \n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import Model\n",
    "\n",
    "from constants import img_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(datagen, data_dir, batch_size, **kwargs):\n",
    "    print('Data directory:', data_dir)\n",
    "    return datagen.flow_from_directory(\n",
    "        data_dir,\n",
    "        target_size=(img_size, img_size),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False,\n",
    "        seed=0,\n",
    "        **kwargs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_model(model_constructor, name, preprocessor, pooling=None, verbose=True, layer=None):    \n",
    "    base_model = model_constructor(include_top=False, weights='imagenet', input_shape=(img_size, img_size, 3), pooling=pooling)\n",
    "    \n",
    "    model = None\n",
    "    if layer == None:\n",
    "        model = base_model\n",
    "    else:\n",
    "        output = base_model.layers[layer].output\n",
    "        \n",
    "        if pooling != None:\n",
    "            output_shape = base_model.layers[layer].output_shape\n",
    "            Pooling = AveragePooling2D if pooling == 'avg' else MaxPooling2D\n",
    "            print(output_shape)\n",
    "            output = Pooling(pool_size=(output_shape[1], output_shape[2]))(output)\n",
    "            \n",
    "        model = Model(input=base_model.input, output=output)\n",
    "    \n",
    "    if verbose == True:\n",
    "        model.summary()\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paths(name):\n",
    "    paths_to_create = [\n",
    "        './features/' + name,\n",
    "    ]\n",
    "    \n",
    "    for path in paths_to_create:\n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "            \n",
    "    return paths_to_create[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractor(model_constructor, name, preprocessor, batch_size, source_dir_train, source_dir_dev, pooling=None, layer=None, verbose = True):\n",
    "    model = base_model(model_constructor, name, preprocessor, pooling, verbose, layer)\n",
    "\n",
    "    datagen = ImageDataGenerator(preprocessing_function=preprocessor)\n",
    "    generator_train = generator(datagen, source_dir_train, batch_size)\n",
    "    generator_dev = generator(datagen, source_dir_dev, batch_size)\n",
    "    \n",
    "    path = paths(name)\n",
    "    print('Path:', path)\n",
    "    np.save(path + '/filenames_train.npy', generator_train.filenames)\n",
    "    np.save(path + '/classes_train.npy', generator_train.classes)\n",
    "    np.save(path + '/filenames_dev.npy', generator_dev.filenames)\n",
    "    np.save(path + '/classes_dev.npy', generator_dev.classes)\n",
    "    \n",
    "    #train features\n",
    "    features_train = model.predict_generator(generator_train, len(generator_train), verbose=1)\n",
    "    np.save(path + '/features_train.npy', features_train)\n",
    "    \n",
    "    #dev features\n",
    "    features_dev = model.predict_generator(generator_dev, len(generator_dev), verbose=1)\n",
    "    np.save(path + '/features_dev.npy', features_dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor(\n",
    "    model_constructor=ResNet50, \n",
    "    name='res_net', \n",
    "    preprocessor=resnet50_preprocess_input, \n",
    "    batch_size=8, \n",
    "#    layer=16,\n",
    "    pooling='avg',\n",
    "    source_dir_train='stanford-car-dataset-by-classes-folder/train_dataset/',\n",
    "    source_dir_dev='stanford-car-dataset-by-classes-folder/dev_dataset/',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor(\n",
    "    model_constructor=InceptionV3, \n",
    "    name='inception', \n",
    "    preprocessor=inception_preprocess_input, \n",
    "    batch_size=8, \n",
    "#    layer=16,\n",
    "    pooling='avg',\n",
    "    source_dir_train='stanford-car-dataset-by-classes-folder/train_dataset/',\n",
    "    source_dir_dev='stanford-car-dataset-by-classes-folder/dev_dataset/',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor(\n",
    "    model_constructor=Xception, \n",
    "    name='xception', \n",
    "    preprocessor=xception_preprocess_input, \n",
    "    batch_size=8, \n",
    "#    layer=16,\n",
    "    pooling='avg',\n",
    "    source_dir_train='stanford-car-dataset-by-classes-folder/train_dataset/',\n",
    "    source_dir_dev='stanford-car-dataset-by-classes-folder/dev_dataset/',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_features(source, target, nets, mode):\n",
    "    features = []\n",
    "    for net in nets:\n",
    "        features.append(np.load(source + net + '/features_' + mode + '.npy'))\n",
    "    features = np.concatenate(features, axis=1)\n",
    "    np.save(target + 'features_' + mode + '.npy', features)\n",
    "\n",
    "def combine_classes(source, target, names, mode):\n",
    "    classes = []\n",
    "    num_classes = []\n",
    "    for name in names:\n",
    "        cl = np.load(source + 'classes_' + mode + '_' + name + '.npy')\n",
    "        cl = to_categorical(cl)\n",
    "        classes.append(cl)\n",
    "        num_classes.append(cl.shape[1])\n",
    "        \n",
    "    max_num_classes = np.max(num_classes)\n",
    "    \n",
    "    for i, cl in enumerate(classes):\n",
    "        padded = np.pad(\n",
    "            cl, \n",
    "            pad_width=((0, 0), (0, max_num_classes - cl.shape[1])),\n",
    "            mode='constant',\n",
    "            constant_values=((0,0), (0,0)),\n",
    "        )\n",
    "        \n",
    "        np.save(target + 'classes_' + mode + '_' + names[i] + '.npy', padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_features('./features/', './features/combined/', ['res_net', 'inception', 'xception'], 'train')\n",
    "combine_features('./features/', './features/combined/', ['res_net', 'inception', 'xception'], 'dev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_classes('./features/res_net/', './features/combined/', ['make', 'model'], 'train')\n",
    "combine_classes('./features/res_net/', './features/combined/', ['make', 'model'], 'dev')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

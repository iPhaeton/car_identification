{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.utils.np_utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_featuers_by_name(net_name):\n",
    "    features_train = np.load('./features/' + net_name + '/features_train.npy')\n",
    "    features_dev = np.load('./features/'+ net_name +'/features_dev.npy')\n",
    "    return features_train, features_dev\n",
    "\n",
    "def get_features(names):\n",
    "    features_train = []\n",
    "    features_dev = []\n",
    "    for name in names:\n",
    "        train, dev = get_featuers_by_name(name)\n",
    "        features_train.append(train)\n",
    "        features_dev.append(dev)\n",
    "    \n",
    "    features_train = np.concatenate(features_train, axis=1)\n",
    "    features_dev = np.concatenate(features_dev, axis=1)\n",
    "    return np.stack([features_train, features_train], axis=1), np.stack([features_dev, features_dev], axis=1)\n",
    "\n",
    "def get_classes_by_name(name):\n",
    "    classes_train = np.load('./features/res_net/classes_train_' + name + '.npy')\n",
    "    filenames_train = np.load('./features/res_net/filenames_train.npy')\n",
    "    classes_train = to_categorical(classes_train)\n",
    "    classes_dev = np.load('./features/res_net/classes_dev_' + name + '.npy')\n",
    "    filenames_dev = np.load('./features/res_net/filenames_dev.npy')\n",
    "    classes_dev = to_categorical(classes_dev)\n",
    "    return classes_train, classes_dev, filenames_train, filenames_dev\n",
    "\n",
    "def get_classes(names):\n",
    "    classes_train = []\n",
    "    classes_dev = []\n",
    "    num_classes = []\n",
    "    for name in names:\n",
    "        train, dev, filenames_train, filenames_dev = get_classes_by_name(name)\n",
    "        classes_train.append(train)\n",
    "        classes_dev.append(dev)\n",
    "        num_classes.append(train.shape[1])\n",
    "        \n",
    "    max_num_classes = np.max(num_classes)\n",
    "    \n",
    "    padded_classes_train = []\n",
    "    padded_classes_dev = []\n",
    "    for train, dev in zip(classes_train, classes_dev):\n",
    "        padded_classes_train.append(\n",
    "            np.pad(\n",
    "                train, \n",
    "                pad_width=((0, 0), (0, max_num_classes - train.shape[1])),\n",
    "                mode='constant',\n",
    "                constant_values=((0,0), (0,0)),\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        padded_classes_dev.append(\n",
    "            np.pad(\n",
    "                dev, \n",
    "                pad_width=((0, 0), (0, max_num_classes - dev.shape[1])),\n",
    "                mode='constant',\n",
    "                constant_values=((0,0), (0,0)),\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    return np.stack(padded_classes_train, axis=1), np.stack(padded_classes_dev, axis=1), filenames_train, filenames_dev\n",
    "\n",
    "def shuffle(data, classes):\n",
    "    assert data.shape[0] == classes.shape[0]\n",
    "    indices = np.random.permutation(data.shape[0])\n",
    "    return data[indices], classes[indices]\n",
    "\n",
    "def preprocess(path, nets, names, batch_size, save=True):\n",
    "    features_train, features_dev = get_features(nets)\n",
    "    classes_train, classes_dev, _, __ = get_classes(names)\n",
    "    \n",
    "    features_train, classes_train = shuffle(features_train, classes_train)\n",
    "    features_dev, classes_dev = shuffle(features_dev, classes_dev)\n",
    "    \n",
    "    if save != True:\n",
    "        return\n",
    "\n",
    "    for i in range(features_train.shape[0] // batch_size + 1):\n",
    "        np.save(\n",
    "            path + str(len(names)) + '_steps' + '/features_train_' + str(i) + '.npy', \n",
    "            features_train[i * batch_size : i * batch_size + batch_size, :, :],\n",
    "        )\n",
    "        \n",
    "        np.save(\n",
    "            path + str(len(names)) + '_steps' + '/classes_train_' + str(i) + '.npy', \n",
    "            classes_train[i * batch_size : i * batch_size + batch_size, :, :],\n",
    "        )\n",
    "    print('Train shape: ', features_train.shape, 'Dev shape:', features_dev.shape)\n",
    "        \n",
    "    for i in range(features_dev.shape[0] // batch_size + 1):\n",
    "        np.save(\n",
    "            path + str(len(names)) + '_steps' + '/features_dev_' + str(i) + '.npy', \n",
    "            features_dev[i * batch_size : i * batch_size + batch_size, :, :]\n",
    "        )\n",
    "        np.save(\n",
    "            path + str(len(names)) + '_steps' + '/classes_dev_' + str(i) +'.npy', \n",
    "            classes_dev[i * batch_size : i * batch_size + batch_size, :, :],\n",
    "        )\n",
    "\n",
    "    print('Train classes shape: ', classes_train.shape, 'Dev classes shape:', classes_dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0 ..., 48 48 48]\n",
      "['AM Hummer SUV 2000/00163.jpg' 'AM Hummer SUV 2000/00462.jpg'\n",
      " 'AM Hummer SUV 2000/00887.jpg' ...,\n",
      " 'smart fortwo Convertible 2012/06886.jpg'\n",
      " 'smart fortwo Convertible 2012/07202.jpg'\n",
      " 'smart fortwo Convertible 2012/07236.jpg']\n",
      "[ 77  77  77 ..., 165 165 165]\n",
      "['AM Hummer SUV 2000/00163.jpg' 'AM Hummer SUV 2000/00462.jpg'\n",
      " 'AM Hummer SUV 2000/00887.jpg' ...,\n",
      " 'smart fortwo Convertible 2012/06886.jpg'\n",
      " 'smart fortwo Convertible 2012/07202.jpg'\n",
      " 'smart fortwo Convertible 2012/07236.jpg']\n"
     ]
    }
   ],
   "source": [
    "preprocess(\n",
    "    './features/lstm/',\n",
    "    [\n",
    "        'res_net',\n",
    "        'inception',\n",
    "        'xception',\n",
    "    ],\n",
    "    [\n",
    "        'make', \n",
    "        'model',\n",
    "    ],\n",
    "    128,\n",
    "    #save=False,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

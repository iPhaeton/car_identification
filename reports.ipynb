{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.lstm_encoder import LSTMEncoder\n",
    "from modules.lstm_decoder import LSTMDecoder\n",
    "from modules.lstm_encoder_decoder import LSTMEncoderDecoder\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import LSTM, SimpleRNN, Input, Bidirectional, TimeDistributed, Dropout, Dense, Activation, BatchNormalization\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown, Latex, HTML, clear_output\n",
    "import ipy_table\n",
    "import ipywidgets as widgets\n",
    "from scipy import ndimage\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = [\n",
    "    Dropout(0.2),\n",
    "    Dense(4096, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(2048, activation='relu'),\n",
    "    Dense(2048, activation='relu'),\n",
    "    Bidirectional(LSTM(1024, return_sequences=True)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LSTMEncoder(layers, './features/lstm/2_steps/', weights_path='./convnet_weights/weights.25-0.77.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_dev = encoder.encode('dev')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classnames(classes, classnames):\n",
    "    class_to_classname = {}\n",
    "    for cl, classname in zip(true_classes, true_classnames):\n",
    "        class_to_classname[cl] = classname\n",
    "\n",
    "    unique_classnames = []\n",
    "    for i in range(len(class_to_classname)):\n",
    "        unique_classnames.append(class_to_classname[i])\n",
    "        \n",
    "    return np.array(unique_classnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.load('./features/lstm/2_steps/indices_dev.npy')\n",
    "true_classes = np.load('./features/res_net/classes_dev_make-model.npy')[indices]\n",
    "true_classnames = np.load('./features/res_net/classnames_dev_make-model.npy')[indices]\n",
    "true_filenames = np.load('./features/res_net/filenames_dev.npy')[indices]\n",
    "unique_classnames = get_classnames(true_classes, true_classnames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_predictions_to_classnames(predictions, true_classes, classnames):\n",
    "    classes, indices = np.unique(true_classes, return_index=True)\n",
    "    \n",
    "    class_to_index = {}\n",
    "    for cl, index in zip(classes, indices):\n",
    "        class_to_index[cl] = index\n",
    "    \n",
    "    predicted_classnames = list(map(lambda cl: classnames[class_to_index[cl]], predictions))\n",
    "    return np.array(predicted_classnames)\n",
    "\n",
    "def map_indices_to_classnames(indices, classnames):\n",
    "    return np.array(list(map(lambda i: classnames[i], indices)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = LSTMDecoder(\n",
    "    None, \n",
    "    None, \n",
    "    features_dev, \n",
    "    true_classes, \n",
    "    weights_path='./convnet_weights/lstm/weights.100-0.98.hdf5'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions, probs = decoder.predict('dev')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTM Encoder-Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-63573cd58114>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m encoder_decoder = LSTMEncoderDecoder(\n\u001b[1;32m      2\u001b[0m     \u001b[0msource_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./features/lstm/2_steps/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mweights_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./convnet_weights/weights.12-0.81-71.7.hdf5'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m~/work/car_identification/modules/lstm_encoder_decoder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, source_path, kernel_initializer, weights_path, output_regularizer, reg, lr)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'glorot_uniform'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.00001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'input'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/work/car_identification/modules/lstm_encoder_decoder.py\u001b[0m in \u001b[0;36mget_metadata\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0minput_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'classes_train_0.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfnmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'*features_train_*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfnmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'*features_dev_*'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "encoder_decoder = LSTMEncoderDecoder(\n",
    "    source_path='./features/lstm/2_steps/',\n",
    "    weights_path='./convnet_weights/weights.12-0.81-71.7.hdf5',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classnames = map_predictions_to_classnames(predictions, true_classes, true_classnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_probs = np.max(probs, axis=1)\n",
    "true_class_probs = probs[list(range(len(true_classes))), true_classes]\n",
    "five_top_classes = np.flip(np.argsort(probs, axis=1), axis=1)[:,0:5]\n",
    "five_top_probs = np.array(list(map(lambda f: str(f), np.flip(np.sort(probs, axis=1), axis=1)[:,0:5])))\n",
    "five_top_names = np.array(list(map(lambda f: str(f), map_indices_to_classnames(five_top_classes, unique_classnames))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reports creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, indices = np.unique(true_classes, return_index=True)\n",
    "classnames = true_classnames[indices]\n",
    "directories = list(map(lambda f: f.split('/')[0],true_filenames[indices]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_report = pd.DataFrame({\n",
    "    'name': classnames,\n",
    "    'directory': directories,\n",
    "}, index = classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_classnames = list(map(lambda cl: classes_report['name'][cl], predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples_report = pd.DataFrame({\n",
    "    'filename': true_filenames,\n",
    "    'prediction': predictions,\n",
    "    'real_class': true_classes,\n",
    "    'predicted_name': pred_classnames,\n",
    "    'real_name': true_classnames,\n",
    "    'predicted_correctly': predictions == true_classes,\n",
    "    'predicted_prob': predicted_probs,\n",
    "    'true_class_prob': true_class_probs,\n",
    "    'five_top_names': five_top_names,\n",
    "    'five_top_probs': five_top_probs,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_count = samples_report['real_class'].value_counts()\n",
    "classes_report['count'] = classes_count.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_count = samples_report[samples_report['predicted_correctly'] == True]['real_class'].value_counts()\n",
    "classes_report['correct_predictions_count'] = correct_count.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_report['correct_predictions_percent'] = classes_report['correct_predictions_count'] / classes_report['count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_report():\n",
    "    clear_output()\n",
    "    display(widgets.HBox((dropdown_sort, dropdown_direction)))\n",
    "\n",
    "def display_classes_report(sortBy, direction):\n",
    "    html = pd.DataFrame.to_html(classes_report.sort_values(sortBy, ascending=direction))\n",
    "    display(HTML(html))\n",
    "    \n",
    "def clear_and_display_report(sortBy, direction):\n",
    "    clear_report()\n",
    "    display_classes_report(sortBy, direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dropdown_sort = widgets.Dropdown(\n",
    "    options=['correct_predictions_percent', 'name', 'count'],\n",
    "    value='correct_predictions_percent',\n",
    "    description='Sort by:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "dropdown_direction = widgets.Dropdown(\n",
    "    options=['ascending', 'descending'],\n",
    "    value='ascending',\n",
    "    description='Direction:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "dropdown_sort.observe(lambda v: \n",
    "                          clear_and_display_report(v['new'], dropdown_direction.value == 'ascending') \n",
    "                          if v['name'] == 'value'\n",
    "                          else None\n",
    "                     )\n",
    "dropdown_direction.observe(lambda v: \n",
    "                              clear_and_display_report(dropdown_sort.value, v['new'] == 'ascending') \n",
    "                              if v['name'] == 'value'\n",
    "                              else None\n",
    "                          )\n",
    "\n",
    "clear_and_display_report(dropdown_sort.value, dropdown_direction.value == 'ascending')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samples report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dropdown_classes = None\n",
    "dropdown_correctness = None\n",
    "dropdown_sample = None\n",
    "\n",
    "def show_sample(row):\n",
    "    clear_output()\n",
    "    display(widgets.HBox((dropdown_classes, dropdown_correctness)))\n",
    "    display(dropdown_sample)\n",
    "    \n",
    "    image = np.array(plt.imread('./stanford-car-dataset-by-classes-folder/car_data/' + row['filename'].iloc[0]))\n",
    "    plt.imshow(image)\n",
    "    print('Classified as: ', row['predicted_name'].iloc[0])\n",
    "    print('Predicted probability: ', row['predicted_prob'].iloc[0])\n",
    "    print('Correct class probability: ', row['true_class_prob'].iloc[0])\n",
    "    print('Five top predictions: ', row['five_top_names'].iloc[0])\n",
    "    print('Five top prediction probs: ', row['five_top_probs'].iloc[0])\n",
    "    filenames = samples_report[samples_report['real_name'] == row['predicted_name'].iloc[0]]['filename']\n",
    "    \n",
    "    images = []\n",
    "    for filename in filenames[0:100]:\n",
    "        images.append(filename)\n",
    "        \n",
    "    fig = plt.figure(figsize=(20,40))\n",
    "    for k in range(10):\n",
    "        for i, image in enumerate(images[k*3:k*3+3]):\n",
    "            img = np.array(plt.imread('./stanford-car-dataset-by-classes-folder/car_data/' + image))\n",
    "            ax = fig.add_subplot(10,3,i + 1 + k * 3)\n",
    "            ax.imshow(img)\n",
    "\n",
    "\n",
    "def show_samples(classname, classification):\n",
    "    global dropdown_sample\n",
    "\n",
    "    df = samples_report[\n",
    "        (samples_report['real_name'] == classname) &\n",
    "        (samples_report['predicted_correctly'] == classification)\n",
    "    ]\n",
    "\n",
    "    if df.shape[0] == 0:\n",
    "        return\n",
    "\n",
    "    dropdown_sample = widgets.Dropdown(\n",
    "        options=df['filename'],\n",
    "        value=df['filename'].iloc[0],\n",
    "        disabled=False,\n",
    "    )\n",
    "    \n",
    "    dropdown_sample.observe(lambda v: show_sample(df[df['filename'] == v['new']]), names='value')\n",
    "    \n",
    "    display(dropdown_sample)\n",
    "    show_sample(df[df['filename'] == df['filename'].iloc[0]])\n",
    "\n",
    "def observe_classes(v):\n",
    "    clear_output()\n",
    "    display(widgets.HBox((dropdown_classes, dropdown_correctness)))\n",
    "    show_samples(v['new'], dropdown_correctness.value == 'classified correctly')\n",
    "    \n",
    "def observe_correctness(v):\n",
    "    clear_output()\n",
    "    show_samples(dropdown_classes.value, v['new'] == 'classified correctly')\n",
    "\n",
    "dropdown_classes = widgets.Dropdown(\n",
    "    options=classnames,\n",
    "    value=classnames[0],\n",
    "    description='Class:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "dropdown_correctness = widgets.Dropdown(\n",
    "    options=['misclassified', 'classified correctly'],\n",
    "    value='misclassified',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "dropdown_classes.observe(observe_classes, names='value')\n",
    "dropdown_correctness.observe(observe_correctness, names='value')\n",
    "\n",
    "display(widgets.HBox((dropdown_classes, dropdown_correctness)))\n",
    "show_samples(classnames[0], dropdown_correctness.value == 'classified correctly')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misclassified as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def show_misclassifications(classname):\n",
    "    df = samples_report[(samples_report['predicted_correctly'] == False) & (samples_report['real_name'] == classname)]\n",
    "    df = pd.DataFrame({'Classified as': df['predicted_name']})\n",
    "    html = pd.DataFrame.to_html(df)\n",
    "    display(HTML(html))\n",
    "    \n",
    "def on_change(v):\n",
    "    clear_output()\n",
    "    display(dropdown)\n",
    "    show_misclassifications(v['new'])\n",
    "\n",
    "dropdown = widgets.Dropdown(\n",
    "    options=classnames,\n",
    "    value=classnames[0],\n",
    "    description='Class:',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "dropdown.observe(on_change, names='value')\n",
    "\n",
    "display(dropdown)\n",
    "show_misclassifications(classnames[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
